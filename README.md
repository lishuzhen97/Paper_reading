# 论文阅读
---
NLP相关的论文，尤其是**文本自动摘要**相关的文章和代码

- [深度学习NLP](#深度学习nlp)
- [预训练模型](#预训练模型)
- [摘要抽取](#摘要抽取)
- [摘要生成](#摘要生成)
-  **BERTSum**: "Fine-tune BERT for Extractive Summarization". arXiv(2019) [[PDF]](https://arxiv.org/pdf/1903.10318.pdf) [[code]](https://github.com/nlpyang/BertSum)
-  **NeuSum**: "Neural Document Summarization by Jointly Learning to Score and Select Sentences". ACL(2018) [[PDF]](https://www.aclweb.org/anthology/P18-1061) 

## 深度学习NLP
- **Transformer**: "Attention is All you Need". NeurIPS(2017) [[PDF]](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)
- **Transformer-XL**: "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context". ACL(2019) [[PDF]](https://www.aclweb.org/anthology/P19-1285) [[code]](https://github.com/kimiyoung/transformer-xl)
[[code-official]](https://github.com/tensorflow/tensor2tensor) [[code-tf]](https://github.com/Kyubyong/transformer) [[code-py]](https://github.com/jadore801120/attention-is-all-you-need-pytorch)
[[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/transform_XL.pdf)
## 预训练模型
- **BERT**: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding". NAACL(2019) [[PDF]](https://www.aclweb.org/anthology/N19-1423) [[code]](https://github.com/google-research/bert) [[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/BERT.pdf) :star::star::star::star::star:
-  **ALBERT**: "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations". ICLR(2020) [[PDF]](https://openreview.net/pdf?id=H1eA7AEtvS)
-  **RoBERTa**: "RoBERTa: A Robustly Optimized BERT Pretraining Approach". arXiv(2019) [[PDF]](https://arxiv.org/pdf/1907.11692.pdf) [[code]](https://github.com/pytorch/fairseq)
-  
## 摘要抽取
- **HIBERT**: "HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization". ACL(2019) [[PDF]](https://doi.org/10.18653/v1/p19-1499)[[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/HIBERT_%E6%9C%AA%E5%BC%80%E6%BA%90.pdf)
- **SummaRuNNer**: "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents" ACL(2019) [[PDF](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14636) [[code]](https://github.com/hpzhao/SummaRuNNer
)[[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/SummaRuNNer.pdf)
-  **SciBERTSUM** "SciBERTSUM: Extractive Summarization for Scientific Documents".CoRR (2022)[[PDF]](https://arxiv.org/abs/2201.08495)[[code]](https://github.com/atharsefid/SciBERTSUM)[[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/SciBERTSUM.pdf)
-  **BERT for Ad Hoc** "Simple Applications of BERT for Ad Hoc Document Retrieval".CoRR(2019)[[PDF]](http://arxiv.org/abs/1903.10972)[[myNote]](https://github.com/lishuzhen97/Paper_reading/blob/main/Papers/Simple%20Applications%20of%20BERT%20for%20Ad%20Hoc%20Document%20Retrieval.pdf)
## 摘要生成

